log-level: INFO
round-number: 2

validation-fraction: 0.05

max-seq-len: 20480
max-tokens: 4096

policy-model: "Qwen/Qwen2.5-Coder-1.5B"
use-bf16: true

full-finetune: true
weight_decay: 0.01

learning-rate: 0.00005

per-device-train-batch-size: 1
per-device-eval-batch-size: 1
gradient-accumulation-steps: 32
num-train-epochs: 1
lr-scheduler-type: "cosine"
warmup-ratio: 0.03
logging-steps: 25
eval-steps: 50
save-steps: 50
save-total-limit: 3
gradient-checkpointing: true

max-train-examples-per-task: 8
val-examples-per-task: 2
test-examples-per-task: 2
max-task-description-chars: 4096
min-active-tasks: 8
max-stagnation-epochs: 16
task-forgetting-threshold: 0.5

report-to: "wandb"

