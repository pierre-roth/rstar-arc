log-level: INFO
round-number: 1

max-seq-len: 12288

reward-model: "Qwen/Qwen2.5-Coder-1.5B"
use-bf16: true


lora-rank: 32
lora-alpha: 32
lora-dropout: 0.2
full-finetune: false
reward-value-head-dropout: 0.1

learning-rate: 0.00004

per-device-train-batch-size: 1
per-device-eval-batch-size: 1
gradient-accumulation-steps: 16
num-train-epochs: 1
lr-scheduler-type: "cosine"
warmup-ratio: 0.03
logging-steps: 50
eval-steps: 100
save-steps: 100
save-total-limit: 3
gradient-checkpointing: true

report-to: "wandb"



