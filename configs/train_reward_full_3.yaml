log-level: INFO
round-number: 6

task-validation-fraction: 0.003
example-validation-num: 1
example-validation-threshold: 5
example-validation-probability: 0.015

max-seq-len: 14336

reward-model: "Qwen/Qwen2.5-Coder-0.5B"
use-bf16: true

full-finetune: true
reward-value-head-dropout: 0.1

training-dataset-name: "reward_dataset_training.jsonl"
validation-dataset-name: "reward_dataset_validation.jsonl"

train-on-prompts: false

learning-rate: 0.00001
weight_decay: 0.05

per-device-train-batch-size: 1
per-device-eval-batch-size: 1
gradient-accumulation-steps: 64

num-train-epochs: 2

lr-scheduler-type: "cosine"
warmup-ratio: 0.03
logging-steps: 50
eval-steps: 100
save-steps: 100
save-total-limit: 2
gradient-checkpointing: true

report-to: "wandb"


